{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93fb8933",
   "metadata": {},
   "source": [
    "# 1. Understanding TOAR data\n",
    "\n",
    "[TOAR Data Infrastructure](https://toar-data.fz-juelich.de/) uses a REST API based data provisioning mechanism which is used to illustrate long range timeseries forecasting tasks using machine learning techniques on air quality data.\n",
    "\n",
    "Initially preliminary analysis is to be performed on the data and subsequently appropriate pre-processing approaches are determined to better forecast future values of the pollutant concentration.\n",
    "\n",
    "The task also iteratively introduces how performance and methodology has evolved systematically from classical ML techniques to recurrent neural networks in forecasting univariate timeseries. Illustrating the advantages and shorcomings in the approach.\n",
    "\n",
    "Finally to demostrate the state of the art capabilities of architectures like transformers which can be leveraged to do multi variate forecasting utilising known past meterological data.\n",
    "\n",
    "> Please note: In case of runtime loss or a need to run any segmented sections of the code make sure to run all the housekeeping cells before it\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13766b33",
   "metadata": {},
   "source": [
    "## Initial Setup and Data download\n",
    "> This section downloads example data from TOAR for 5 stations in Germany. Refer to [TOAR Quick UserGuide](https://toar-data.fz-juelich.de/sphinx/TOAR_UG_Vol02_Quick_Start/build/html/examples.html) examples to better understand data structuring in TOAR that is used in the below snippet to download examples.\n",
    "\n",
    "ðŸ˜ˆ **Question 1:** What are the potential challenges in working with observational environmental data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49eb9d93",
   "metadata": {},
   "source": [
    "### Housekeeping: Initial setup, declarations and method definitions\n",
    "\n",
    "ðŸ˜ˆ **Task 1:** Explore the `station_codes` variable and try changing the station(s) to a different region.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb98c436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\s.vasired\\miniconda3\\envs\\myenv_labex\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\s.vasired\\miniconda3\\envs\\myenv_labex\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: requests in c:\\users\\s.vasired\\miniconda3\\envs\\myenv_labex\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\s.vasired\\miniconda3\\envs\\myenv_labex\\lib\\site-packages (2.19.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\s.vasired\\miniconda3\\envs\\myenv_labex\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\s.vasired\\miniconda3\\envs\\myenv_labex\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\s.vasired\\miniconda3\\envs\\myenv_labex\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\s.vasired\\miniconda3\\envs\\myenv_labex\\lib\\site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\s.vasired\\miniconda3\\envs\\myenv_labex\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\s.vasired\\miniconda3\\envs\\myenv_labex\\lib\\site-packages (from requests) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\s.vasired\\miniconda3\\envs\\myenv_labex\\lib\\site-packages (from requests) (2025.1.31)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\s.vasired\\miniconda3\\envs\\myenv_labex\\lib\\site-packages (from tensorflow) (2.2.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\s.vasired\\miniconda3\\envs\\myenv_labex\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\s.vasired\\miniconda3\\envs\\myenv_labex\\lib\\site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\s.vasired\\miniconda3\\envs\\myenv_labex\\lib\\site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\s.vasired\\miniconda3\\envs\\myenv_labex\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\s.vasired\\miniconda3\\envs\\myenv_labex\\lib\\site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\s.vasired\\miniconda3\\envs\\myenv_labex\\lib\\site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\s.vasired\\miniconda3\\envs\\myenv_labex\\lib\\site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\s.vasired\\miniconda3\\envs\\myenv_labex\\lib\\site-packages (from tensorflow) (5.29.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\s.vasired\\miniconda3\\envs\\myenv_labex\\lib\\site-packages (from tensorflow) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\s.vasired\\miniconda3\\envs\\myenv_labex\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\s.vasired\\miniconda3\\envs\\myenv_labex\\lib\\site-packages (from tensorflow) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\s.vasired\\miniconda3\\envs\\myenv_labex\\lib\\site-packages (from tensorflow) (4.13.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\s.vasired\\miniconda3\\envs\\myenv_labex\\lib\\site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\s.vasired\\miniconda3\\envs\\myenv_labex\\lib\\site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\s.vasired\\miniconda3\\envs\\myenv_labex\\lib\\site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\s.vasired\\miniconda3\\envs\\myenv_labex\\lib\\site-packages (from tensorflow) (3.9.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\s.vasired\\miniconda3\\envs\\myenv_labex\\lib\\site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\s.vasired\\miniconda3\\envs\\myenv_labex\\lib\\site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\s.vasired\\miniconda3\\envs\\myenv_labex\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\s.vasired\\miniconda3\\envs\\myenv_labex\\lib\\site-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
      "Requirement already satisfied: namex in c:\\users\\s.vasired\\miniconda3\\envs\\myenv_labex\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\s.vasired\\miniconda3\\envs\\myenv_labex\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\s.vasired\\miniconda3\\envs\\myenv_labex\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.8)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\s.vasired\\miniconda3\\envs\\myenv_labex\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\s.vasired\\miniconda3\\envs\\myenv_labex\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\s.vasired\\miniconda3\\envs\\myenv_labex\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\s.vasired\\miniconda3\\envs\\myenv_labex\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\s.vasired\\miniconda3\\envs\\myenv_labex\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\s.vasired\\miniconda3\\envs\\myenv_labex\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "# Most notebook servers like google collab should have these packages pre-installed\n",
    "# In such cases this is just a sanity check\n",
    "!pip install pandas numpy requests tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4eba776",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# Global constants\n",
    "TIMESERIES_DATA_DIR = \"./content/timeseries_data/\"\n",
    "TIMESERIES_CSV_DIR = os.path.join(TIMESERIES_DATA_DIR, \"toar_csv_timeseries\")\n",
    "TIMESERIES_ID_FILE = os.path.join(TIMESERIES_DATA_DIR, \"timeseriesIDs.json\")\n",
    "MIN_FILE_SIZE_BYTES = 100\n",
    "group_columns = ['station_code', 'latitude', 'longitude']\n",
    "\n",
    "os.makedirs(TIMESERIES_DATA_DIR, exist_ok=True)\n",
    "os.makedirs(TIMESERIES_CSV_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46af26a1",
   "metadata": {},
   "source": [
    "Custom range selection for experiments\n",
    "\n",
    "station codes in the example snippet below are checked for a common range for the chosen variables, however if you prefer to experiment with ranges you might want to check using [Search API](https://toar-data.fz-juelich.de/api/v2/#search-combined-endpoint-of-stations-and-timeseries) for the date range for which data is available for a particular variable, station and source combination. As the TOAR is observational data provided via different contributing sources and has vast missing data.\n",
    "\n",
    "ðŸ˜ˆ **Question 2:** Why might there be gaps in observational data from TOAR?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9663fef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# German stations with good distribution o3 variable observations\n",
    "# station_codes = [\"DENW094\", \"DEBW073\",\"DEBB029\",\"DEBE051\",\"DEHE020\"]\n",
    "station_codes = [\"DENW094\"]\n",
    "variable_columns = [\"no2\", \"temp\", \"o3\", \"no\", \"press\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d99569",
   "metadata": {},
   "source": [
    "Below methods each have appropriate documentation and comments to illustrate the logical flow *(they are placed with enough safeguards against both the API and optimized to avoid re-downloads when interupted during partial downloads to accomodate any loss of runtime on platforms like google colab)* and briefly described here for ease of use\n",
    ">\n",
    "\n",
    "ðŸ˜ˆ **Task 2:** Inspect the function `pivot_handle()`. What does it return, and why is pivoting important for time series analysis?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef2eebb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_existing_timeseries_ids():\n",
    "    \"\"\"\n",
    "    Load existing timeseries IDs from a JSON file.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing stored timeseries metadata.\n",
    "    \"\"\"\n",
    "    return json.load(open(TIMESERIES_ID_FILE, 'r')) if os.path.exists(TIMESERIES_ID_FILE) else {}\n",
    "\n",
    "def save_timeseries_ids(timeseries_data):\n",
    "    \"\"\"\n",
    "    Save timeseries metadata to a JSON file.\n",
    "\n",
    "    Args:\n",
    "        timeseries_data (dict): A dictionary containing timeseries metadata.\n",
    "    \"\"\"\n",
    "    json.dump(timeseries_data, open(TIMESERIES_ID_FILE, 'w'), indent=4)\n",
    "\n",
    "def fetch_timeseries_data(station_codes, existing_timeseries, variable_columns):\n",
    "    \"\"\"\n",
    "    Fetch timeseries metadata for given station codes, filtering by specified variables.\n",
    "\n",
    "    Args:\n",
    "        station_codes (list): List of station codes to fetch data for.\n",
    "        existing_timeseries (dict): Dictionary of previously fetched timeseries metadata.\n",
    "        variable_columns (list): List of variable names to retain.\n",
    "\n",
    "    Returns:\n",
    "        dict: Updated dictionary containing filtered timeseries metadata.\n",
    "    \"\"\"\n",
    "    base_url = \"http://toar-data.fz-juelich.de/api/v2/search/?codes=\"\n",
    "    unique_entries = existing_timeseries.copy()\n",
    "    processed_station_codes = {details['station_code'] for details in existing_timeseries.values()}\n",
    "\n",
    "    for code in station_codes:\n",
    "        if code in processed_station_codes:\n",
    "            print(f\"\\t\\tStation {code} is already processed, skipping.\")\n",
    "            continue\n",
    "\n",
    "        response = requests.get(base_url + code, timeout=1000)\n",
    "        if response.status_code == 200:\n",
    "            for entry in response.json():\n",
    "                if (variable_name := entry.get('variable', {}).get('name')) in variable_columns:\n",
    "                    timeseries_id = entry.get('id')\n",
    "                    if timeseries_id not in unique_entries:\n",
    "                        unique_entries[timeseries_id] = {\n",
    "                            'data_start_date': entry.get('data_start_date'),\n",
    "                            'data_end_date': entry.get('data_end_date'),\n",
    "                            'variable_name': variable_name,\n",
    "                            'station_code': code,\n",
    "                            'latitude': entry.get('station', {}).get('coordinates', {}).get('lat'),\n",
    "                            'longitude': entry.get('station', {}).get('coordinates', {}).get('lng'),\n",
    "                        }\n",
    "        else:\n",
    "            print(f\"\\t\\tFailed to fetch data for station {code}. Status code: {response.status_code}\")\n",
    "    return unique_entries\n",
    "\n",
    "def pivot_handle(dfs, metadata_columns, variable_columns):\n",
    "    \"\"\"\n",
    "    Pivot and structure the timeseries dataframe for sequential data analysis.\n",
    "\n",
    "    Args:\n",
    "        dfs (pd.DataFrame): Dataframe containing timeseries data.\n",
    "        metadata_columns (list): List of metadata column names.\n",
    "        variable_columns (list): List of variable names to include.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Processed dataframe with pivoted structure.\n",
    "    \"\"\"\n",
    "    dfs = dfs[dfs['variable_name'].isin(variable_columns)]\n",
    "    pivot_df = dfs.pivot(index='datetime', columns='variable_name', values='value').reset_index()\n",
    "    return dfs[metadata_columns].drop_duplicates(subset=['datetime']).merge(pivot_df, on='datetime', how='left')\n",
    "\n",
    "def download_csv_data(timeseries_data, variable_columns):\n",
    "    \"\"\"\n",
    "    Download and process CSV data for each timeseries ID.\n",
    "\n",
    "    Args:\n",
    "        timeseries_data (dict): Dictionary containing timeseries metadata.\n",
    "        variable_columns (list): List of variable names to process.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Combined dataframe of all timeseries data.\n",
    "    \"\"\"\n",
    "    dataframes = []\n",
    "    metadata_columns = ['datetime', 'station_code', 'latitude', 'longitude']\n",
    "\n",
    "    for ts_id, details in timeseries_data.items():\n",
    "        csv_path = os.path.join(TIMESERIES_CSV_DIR, f\"{ts_id}.csv\")\n",
    "\n",
    "        if os.path.exists(csv_path) and os.path.getsize(csv_path) > MIN_FILE_SIZE_BYTES:\n",
    "            print(f\"\\tCSV already exists for timeseries ID {ts_id}, skipping download.\")\n",
    "        else:\n",
    "            print(f\"\\tDownloading data for timeseries ID {ts_id}\")\n",
    "            url = f\"http://toar-data.fz-juelich.de/api/v2/data/timeseries/{ts_id}?format=csv\"\n",
    "            try:\n",
    "                response = requests.get(url, stream=True, timeout=1000)\n",
    "                response.raise_for_status()\n",
    "                with open(csv_path, 'wb') as file:\n",
    "                    file.writelines(response.iter_content(chunk_size=8192))\n",
    "                print(f\"\\t\\tRaw data CSV of {ts_id} saved: {csv_path}\")\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"\\t\\tFailed to download data for timeseries ID {ts_id}. Error: {e}\")\n",
    "                continue\n",
    "\n",
    "        try:\n",
    "            df = pd.read_csv(csv_path, skiprows=lambda i: i < next(i for i, line in enumerate(open(csv_path)) if line.startswith('datetime')), low_memory=False)\n",
    "            df['datetime'] = pd.to_datetime(df['datetime'], format='mixed')\n",
    "            df[['variable_name', 'station_code', 'latitude', 'longitude']] = details['variable_name'], details['station_code'], details['latitude'], details['longitude']\n",
    "            print(f\"Dataframe for timeseries ID {ts_id} loaded successfully with shape {df.shape}\")\n",
    "            dataframes.append(pivot_handle(df, metadata_columns, variable_columns))\n",
    "        except (pd.errors.EmptyDataError, pd.errors.ParserError) as e:\n",
    "            print(f\"\\tError processing CSV for timeseries ID {ts_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "    return pd.concat(dataframes, ignore_index=True).sort_values(by=['station_code', 'datetime']) if dataframes else pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dab0925",
   "metadata": {},
   "source": [
    "### Download via REST API\n",
    "\n",
    "ðŸ˜ˆ **Task 3:** Try downloading a different variable or add another pollutant (e.g., `so2`). What changes?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c3464c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tStation DENW094 is already processed, skipping.\n",
      "\t Number of time series meta data fetched : 5\n",
      "\tCSV already exists for timeseries ID 73, skipping download.\n",
      "Dataframe for timeseries ID 73 loaded successfully with shape (209839, 9)\n",
      "\tCSV already exists for timeseries ID 74, skipping download.\n",
      "Dataframe for timeseries ID 74 loaded successfully with shape (208896, 9)\n",
      "\tCSV already exists for timeseries ID 75, skipping download.\n",
      "Dataframe for timeseries ID 75 loaded successfully with shape (207375, 9)\n",
      "\tCSV already exists for timeseries ID 76, skipping download.\n",
      "Dataframe for timeseries ID 76 loaded successfully with shape (245086, 9)\n",
      "\tCSV already exists for timeseries ID 80, skipping download.\n",
      "Dataframe for timeseries ID 80 loaded successfully with shape (160608, 9)\n",
      "\t Total dataFrames processed : 1031804 and shape of first dataframe (1031804, 9).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>station_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>o3</th>\n",
       "      <th>no2</th>\n",
       "      <th>no</th>\n",
       "      <th>temp</th>\n",
       "      <th>press</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>626110</th>\n",
       "      <td>1997-01-01 00:00:00+00:00</td>\n",
       "      <td>DENW094</td>\n",
       "      <td>50.754704</td>\n",
       "      <td>6.093923</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-15.85</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626111</th>\n",
       "      <td>1997-01-01 01:00:00+00:00</td>\n",
       "      <td>DENW094</td>\n",
       "      <td>50.754704</td>\n",
       "      <td>6.093923</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-16.35</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626112</th>\n",
       "      <td>1997-01-01 02:00:00+00:00</td>\n",
       "      <td>DENW094</td>\n",
       "      <td>50.754704</td>\n",
       "      <td>6.093923</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-16.45</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626113</th>\n",
       "      <td>1997-01-01 03:00:00+00:00</td>\n",
       "      <td>DENW094</td>\n",
       "      <td>50.754704</td>\n",
       "      <td>6.093923</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-17.15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626114</th>\n",
       "      <td>1997-01-01 04:00:00+00:00</td>\n",
       "      <td>DENW094</td>\n",
       "      <td>50.754704</td>\n",
       "      <td>6.093923</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-17.35</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        datetime station_code   latitude  longitude  o3  no2  \\\n",
       "626110 1997-01-01 00:00:00+00:00      DENW094  50.754704   6.093923 NaN  NaN   \n",
       "626111 1997-01-01 01:00:00+00:00      DENW094  50.754704   6.093923 NaN  NaN   \n",
       "626112 1997-01-01 02:00:00+00:00      DENW094  50.754704   6.093923 NaN  NaN   \n",
       "626113 1997-01-01 03:00:00+00:00      DENW094  50.754704   6.093923 NaN  NaN   \n",
       "626114 1997-01-01 04:00:00+00:00      DENW094  50.754704   6.093923 NaN  NaN   \n",
       "\n",
       "        no   temp  press  \n",
       "626110 NaN -15.85    NaN  \n",
       "626111 NaN -16.35    NaN  \n",
       "626112 NaN -16.45    NaN  \n",
       "626113 NaN -17.15    NaN  \n",
       "626114 NaN -17.35    NaN  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load existing timeseries IDs from json to skip calls to TOAR\n",
    "existing_timeseries = load_existing_timeseries_ids()\n",
    "\n",
    "timeseries_data = fetch_timeseries_data(station_codes, existing_timeseries,variable_columns)\n",
    "print(f\"\\t Number of time series meta data fetched : {len(timeseries_data)}\")\n",
    "\n",
    "# save existing timeseries IDs as json to reduce calls to TOAR in future\n",
    "save_timeseries_ids(timeseries_data)\n",
    "\n",
    "dataframes = download_csv_data(timeseries_data,variable_columns)\n",
    "print(f\"\\t Total dataFrames processed : {len(dataframes)} and shape of first dataframe {dataframes.shape}.\")\n",
    "\n",
    "dataframes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c8d25f",
   "metadata": {},
   "source": [
    "As the TOAR is observational data provided via different contributing sources and has vast missing data, we expect the NAs despite finding a common date range and need to check how many missing values (NAs) there are for each variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2588a2f2",
   "metadata": {},
   "source": [
    "## Data handling (observational gaps)\n",
    "\n",
    "Once we know that, we can figure out the best way to fill in the gaps, like using interpolation or making the data more consistent. In our case as the data is towards pollutant concentration and data is hourly, we can safely fill a consecutive 6 hour window without compromising the quality of the data\n",
    "\n",
    "ðŸ˜ˆ **Question 3:** Why is it acceptable to fill up to 6 missing hourly values in this dataset?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0237f955",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def fill_six_nans(group):\n",
    "    \"\"\"\n",
    "    Fills up to six consecutive NaN values in a given pandas Series using linear interpolation\n",
    "    if the NaNs are surrounded by valid values. If the NaNs are at the start, they are replaced\n",
    "    with zeros, and if they are at the end, they are filled with the last known value.\n",
    "\n",
    "    Args:\n",
    "        group (pd.Series): The input Series with potential NaN values.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: A Series where up to six consecutive NaNs are interpolated, and longer NaN\n",
    "        sequences are partially filled while preserving the original index.\n",
    "    \"\"\"\n",
    "    values = group.to_numpy()\n",
    "    i = 0\n",
    "    while i < len(values):\n",
    "        if np.isnan(values[i]):\n",
    "            start = i\n",
    "            while i < len(values) and np.isnan(values[i]):\n",
    "                i += 1\n",
    "            end = min(i, start + 6)  # Limit to filling only 6 NaNs\n",
    "\n",
    "            if start > 0 and i < len(values):  # NaNs in the middle\n",
    "                fill_values = np.linspace(values[start - 1], values[i], end - start + 2)[1:-1]\n",
    "            elif start == 0:  # NaNs at the start\n",
    "                fill_values = [0] * (end - start)\n",
    "            elif i >= len(values):  # NaNs at the end\n",
    "                fill_values = [values[start - 1]] * (end - start)\n",
    "            values[start:end] = fill_values\n",
    "        else:\n",
    "            i += 1\n",
    "    return pd.Series(values, index=group.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d861e5dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime             0\n",
       "station_code         0\n",
       "latitude             0\n",
       "longitude            0\n",
       "o3               50259\n",
       "no2              44988\n",
       "no               50485\n",
       "temp              3521\n",
       "press           265219\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes[variable_columns] = dataframes.groupby(group_columns)[variable_columns].transform(fill_six_nans)\n",
    "dataframes.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67c220f",
   "metadata": {},
   "source": [
    "Now rest of the Nas can be dropped as that station might not have data collected in the time period and the data needs to be normalized.\n",
    "\n",
    "ðŸ˜ˆ **Task 4:** What risks might arise if normalization is applied *before* handling missing values?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "079160de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime        0\n",
       "station_code    0\n",
       "latitude        0\n",
       "longitude       0\n",
       "o3              0\n",
       "no2             0\n",
       "no              0\n",
       "temp            0\n",
       "press           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes = dataframes.dropna()\n",
    "dataframes.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e2b6ef96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(702894, 9)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3618005c",
   "metadata": {},
   "source": [
    "## Staged data loading (Housekeeping)\n",
    "\n",
    "To proceed with any analysis now the normalized data can be reloaded from local when needed (In case of runtime losses) to continue with ML experiments rather than re-downloading and normalizing again.\n",
    "\n",
    "ðŸ˜ˆ **Task 5:** Modify this section to reload data from a custom path or add a parameter to toggle reloading.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e51c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes.to_csv(os.path.join(TIMESERIES_DATA_DIR, \"raw_data.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c18223",
   "metadata": {},
   "source": [
    "Below cell can be used to reload data if using an open source notebook servers like google colab and the if the usage limit is reached or for other issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626bfaba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>station_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>o3</th>\n",
       "      <th>no2</th>\n",
       "      <th>no</th>\n",
       "      <th>temp</th>\n",
       "      <th>press</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997-01-01 00:00:00+00:00</td>\n",
       "      <td>DENW094</td>\n",
       "      <td>50.754704</td>\n",
       "      <td>6.093923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-15.85</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997-01-01 01:00:00+00:00</td>\n",
       "      <td>DENW094</td>\n",
       "      <td>50.754704</td>\n",
       "      <td>6.093923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-16.35</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997-01-01 02:00:00+00:00</td>\n",
       "      <td>DENW094</td>\n",
       "      <td>50.754704</td>\n",
       "      <td>6.093923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-16.45</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997-01-01 03:00:00+00:00</td>\n",
       "      <td>DENW094</td>\n",
       "      <td>50.754704</td>\n",
       "      <td>6.093923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-17.15</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1997-01-01 04:00:00+00:00</td>\n",
       "      <td>DENW094</td>\n",
       "      <td>50.754704</td>\n",
       "      <td>6.093923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-17.35</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    datetime station_code   latitude  longitude   o3  no2  \\\n",
       "0  1997-01-01 00:00:00+00:00      DENW094  50.754704   6.093923  0.0  0.0   \n",
       "1  1997-01-01 01:00:00+00:00      DENW094  50.754704   6.093923  0.0  0.0   \n",
       "2  1997-01-01 02:00:00+00:00      DENW094  50.754704   6.093923  0.0  0.0   \n",
       "3  1997-01-01 03:00:00+00:00      DENW094  50.754704   6.093923  0.0  0.0   \n",
       "4  1997-01-01 04:00:00+00:00      DENW094  50.754704   6.093923  0.0  0.0   \n",
       "\n",
       "    no   temp  press  \n",
       "0  0.0 -15.85    0.0  \n",
       "1  0.0 -16.35    0.0  \n",
       "2  0.0 -16.45    0.0  \n",
       "3  0.0 -17.15    0.0  \n",
       "4  0.0 -17.35    0.0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "## Normalized data csv is also made available for the select stations in URL:\n",
    "# https://drive.google.com/file/d/1ohReYdUgtBFogeAmxghPo3_Qa9RnzxSh/view?usp=drive_link\n",
    "# \"C:\\content\\timeseries_data\\raw_data.csv\"\n",
    "dataframes = pd.read_csv(os.path.join(TIMESERIES_DATA_DIR, \"raw_data.csv\"))\n",
    "dataframes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b9d4b72a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(702894, 9)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "44b4e968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime        0\n",
       "station_code    0\n",
       "latitude        0\n",
       "longitude       0\n",
       "o3              0\n",
       "no2             0\n",
       "no              0\n",
       "temp            0\n",
       "press           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7426db96",
   "metadata": {},
   "source": [
    "### Statistical Analysis\n",
    "\n",
    "The data can now be analysed for basic statistical tendencies or measures like (note standard measures are indicated here, but you can run custom measures as well)\n",
    "\n",
    "ðŸ˜ˆ **Task 6:** Create a boxplot for `no2` and `o3` by station to visualize spread and outliers.\n",
    "\n",
    "ðŸ˜ˆ **Question 4:** Which station shows the highest variance in `no2`? What might explain this?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1205a5d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">no2</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">press</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>sum</th>\n",
       "      <th>std</th>\n",
       "      <th>var</th>\n",
       "      <th>median</th>\n",
       "      <th>prod</th>\n",
       "      <th>nunique</th>\n",
       "      <th>5th_percentile</th>\n",
       "      <th>...</th>\n",
       "      <th>std</th>\n",
       "      <th>var</th>\n",
       "      <th>median</th>\n",
       "      <th>prod</th>\n",
       "      <th>nunique</th>\n",
       "      <th>5th_percentile</th>\n",
       "      <th>10th_percentile</th>\n",
       "      <th>25th_percentile</th>\n",
       "      <th>50th_percentile</th>\n",
       "      <th>75th_percentile</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DENW094</th>\n",
       "      <td>-2.544249</td>\n",
       "      <td>81.321835</td>\n",
       "      <td>7.574944</td>\n",
       "      <td>5.324383e+06</td>\n",
       "      <td>6.359106</td>\n",
       "      <td>40.438231</td>\n",
       "      <td>5.648024</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>282352</td>\n",
       "      <td>1.250368</td>\n",
       "      <td>...</td>\n",
       "      <td>9.809127</td>\n",
       "      <td>96.218972</td>\n",
       "      <td>993.193265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162452</td>\n",
       "      <td>975.436169</td>\n",
       "      <td>980.0</td>\n",
       "      <td>987.048013</td>\n",
       "      <td>993.193265</td>\n",
       "      <td>998.912165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   no2                                               \\\n",
       "                   min        max      mean           sum       std   \n",
       "station_code                                                          \n",
       "DENW094      -2.544249  81.321835  7.574944  5.324383e+06  6.359106   \n",
       "\n",
       "                                                               ...     press  \\\n",
       "                    var    median prod nunique 5th_percentile  ...       std   \n",
       "station_code                                                   ...             \n",
       "DENW094       40.438231  5.648024 -0.0  282352       1.250368  ...  9.809127   \n",
       "\n",
       "                                                                 \\\n",
       "                    var      median prod nunique 5th_percentile   \n",
       "station_code                                                      \n",
       "DENW094       96.218972  993.193265  0.0  162452     975.436169   \n",
       "\n",
       "                                                                              \n",
       "             10th_percentile 25th_percentile 50th_percentile 75th_percentile  \n",
       "station_code                                                                  \n",
       "DENW094                980.0      987.048013      993.193265      998.912165  \n",
       "\n",
       "[1 rows x 70 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'min'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no2</th>\n",
       "      <th>temp</th>\n",
       "      <th>o3</th>\n",
       "      <th>no</th>\n",
       "      <th>press</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DENW094</th>\n",
       "      <td>-2.544249</td>\n",
       "      <td>-17.35</td>\n",
       "      <td>-1.417507</td>\n",
       "      <td>-3.360428</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   no2   temp        o3        no  press\n",
       "station_code                                            \n",
       "DENW094      -2.544249 -17.35 -1.417507 -3.360428    0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'max'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no2</th>\n",
       "      <th>temp</th>\n",
       "      <th>o3</th>\n",
       "      <th>no</th>\n",
       "      <th>press</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DENW094</th>\n",
       "      <td>81.321835</td>\n",
       "      <td>39.126</td>\n",
       "      <td>134.83356</td>\n",
       "      <td>447.81647</td>\n",
       "      <td>1023.717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    no2    temp         o3         no     press\n",
       "station_code                                                   \n",
       "DENW094       81.321835  39.126  134.83356  447.81647  1023.717"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'mean'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no2</th>\n",
       "      <th>temp</th>\n",
       "      <th>o3</th>\n",
       "      <th>no</th>\n",
       "      <th>press</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DENW094</th>\n",
       "      <td>7.574944</td>\n",
       "      <td>10.681479</td>\n",
       "      <td>24.706104</td>\n",
       "      <td>3.301909</td>\n",
       "      <td>992.486596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   no2       temp         o3        no       press\n",
       "station_code                                                      \n",
       "DENW094       7.574944  10.681479  24.706104  3.301909  992.486596"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'std'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no2</th>\n",
       "      <th>temp</th>\n",
       "      <th>o3</th>\n",
       "      <th>no</th>\n",
       "      <th>press</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station_code</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DENW094</th>\n",
       "      <td>6.359106</td>\n",
       "      <td>7.438985</td>\n",
       "      <td>14.647992</td>\n",
       "      <td>8.883813</td>\n",
       "      <td>9.809127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   no2      temp         o3        no     press\n",
       "station_code                                                   \n",
       "DENW094       6.359106  7.438985  14.647992  8.883813  9.809127"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stats = ['min', 'max', 'mean', 'sum', 'std', 'var', 'median','prod','nunique',\n",
    "    ('5th_percentile', lambda x: x.quantile(0.05)),\n",
    "    ('10th_percentile', lambda x: x.quantile(0.10)),\n",
    "    ('25th_percentile', lambda x: x.quantile(0.25)),\n",
    "    ('50th_percentile', lambda x: x.quantile(0.50)), #(median)\n",
    "    ('75th_percentile', lambda x: x.quantile(0.75))]\n",
    "agg_dict = {col: stats for col in variable_columns}\n",
    "grouped = dataframes.groupby('station_code').agg(agg_dict)\n",
    "display(grouped)  \n",
    "\n",
    "for agg_func in ['min', 'max', 'mean', 'std']:\n",
    "    display(agg_func)\n",
    "    agg_view = grouped.xs(agg_func, axis=1, level=1) \n",
    "    display(agg_view)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a1fc90",
   "metadata": {},
   "source": [
    "## Data Preprocessing (Normalization)\n",
    "\n",
    "the snippet below uses standard Z normalization (this is a simple snippet alternatively other approaches could also be used as desired)\n",
    "\n",
    "\n",
    "ðŸ˜ˆ **Task 7:** Implement min-max normalization and compare the results visually with Z-score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8a947a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scaler(df, columns):\n",
    "    \"\"\"\n",
    "    Standardize the specified columns of a DataFrame by subtracting the mean\n",
    "    and dividing by the standard deviation (Z-score normalization).\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        columns (list): List of column names to be normalized.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with normalized columns.\n",
    "    \"\"\"\n",
    "    df_scaled = df.copy()\n",
    "    for col in columns:\n",
    "        mean = df_scaled[col].mean()\n",
    "        std = df_scaled[col].std()\n",
    "        df_scaled[col] = (df_scaled[col] - mean) / std\n",
    "    return df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ff0651c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>station_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>o3</th>\n",
       "      <th>no2</th>\n",
       "      <th>no</th>\n",
       "      <th>temp</th>\n",
       "      <th>press</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997-01-01 00:00:00+00:00</td>\n",
       "      <td>DENW094</td>\n",
       "      <td>50.754704</td>\n",
       "      <td>6.093923</td>\n",
       "      <td>-1.686655</td>\n",
       "      <td>-1.191196</td>\n",
       "      <td>-0.371677</td>\n",
       "      <td>-3.566546</td>\n",
       "      <td>-101.179911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997-01-01 01:00:00+00:00</td>\n",
       "      <td>DENW094</td>\n",
       "      <td>50.754704</td>\n",
       "      <td>6.093923</td>\n",
       "      <td>-1.686655</td>\n",
       "      <td>-1.191196</td>\n",
       "      <td>-0.371677</td>\n",
       "      <td>-3.633759</td>\n",
       "      <td>-101.179911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997-01-01 02:00:00+00:00</td>\n",
       "      <td>DENW094</td>\n",
       "      <td>50.754704</td>\n",
       "      <td>6.093923</td>\n",
       "      <td>-1.686655</td>\n",
       "      <td>-1.191196</td>\n",
       "      <td>-0.371677</td>\n",
       "      <td>-3.647202</td>\n",
       "      <td>-101.179911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997-01-01 03:00:00+00:00</td>\n",
       "      <td>DENW094</td>\n",
       "      <td>50.754704</td>\n",
       "      <td>6.093923</td>\n",
       "      <td>-1.686655</td>\n",
       "      <td>-1.191196</td>\n",
       "      <td>-0.371677</td>\n",
       "      <td>-3.741301</td>\n",
       "      <td>-101.179911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1997-01-01 04:00:00+00:00</td>\n",
       "      <td>DENW094</td>\n",
       "      <td>50.754704</td>\n",
       "      <td>6.093923</td>\n",
       "      <td>-1.686655</td>\n",
       "      <td>-1.191196</td>\n",
       "      <td>-0.371677</td>\n",
       "      <td>-3.768186</td>\n",
       "      <td>-101.179911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    datetime station_code   latitude  longitude        o3  \\\n",
       "0  1997-01-01 00:00:00+00:00      DENW094  50.754704   6.093923 -1.686655   \n",
       "1  1997-01-01 01:00:00+00:00      DENW094  50.754704   6.093923 -1.686655   \n",
       "2  1997-01-01 02:00:00+00:00      DENW094  50.754704   6.093923 -1.686655   \n",
       "3  1997-01-01 03:00:00+00:00      DENW094  50.754704   6.093923 -1.686655   \n",
       "4  1997-01-01 04:00:00+00:00      DENW094  50.754704   6.093923 -1.686655   \n",
       "\n",
       "        no2        no      temp       press  \n",
       "0 -1.191196 -0.371677 -3.566546 -101.179911  \n",
       "1 -1.191196 -0.371677 -3.633759 -101.179911  \n",
       "2 -1.191196 -0.371677 -3.647202 -101.179911  \n",
       "3 -1.191196 -0.371677 -3.741301 -101.179911  \n",
       "4 -1.191196 -0.371677 -3.768186 -101.179911  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes = standard_scaler(dataframes, variable_columns)\n",
    "dataframes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bad453c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes.to_csv(os.path.join(TIMESERIES_DATA_DIR, \"normalized_data.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "296a3eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>station_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>o3</th>\n",
       "      <th>no2</th>\n",
       "      <th>no</th>\n",
       "      <th>temp</th>\n",
       "      <th>press</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997-01-01 00:00:00+00:00</td>\n",
       "      <td>DENW094</td>\n",
       "      <td>50.754704</td>\n",
       "      <td>6.093923</td>\n",
       "      <td>-1.686655</td>\n",
       "      <td>-1.191196</td>\n",
       "      <td>-0.371677</td>\n",
       "      <td>-3.566546</td>\n",
       "      <td>-101.179911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997-01-01 01:00:00+00:00</td>\n",
       "      <td>DENW094</td>\n",
       "      <td>50.754704</td>\n",
       "      <td>6.093923</td>\n",
       "      <td>-1.686655</td>\n",
       "      <td>-1.191196</td>\n",
       "      <td>-0.371677</td>\n",
       "      <td>-3.633759</td>\n",
       "      <td>-101.179911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997-01-01 02:00:00+00:00</td>\n",
       "      <td>DENW094</td>\n",
       "      <td>50.754704</td>\n",
       "      <td>6.093923</td>\n",
       "      <td>-1.686655</td>\n",
       "      <td>-1.191196</td>\n",
       "      <td>-0.371677</td>\n",
       "      <td>-3.647202</td>\n",
       "      <td>-101.179911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997-01-01 03:00:00+00:00</td>\n",
       "      <td>DENW094</td>\n",
       "      <td>50.754704</td>\n",
       "      <td>6.093923</td>\n",
       "      <td>-1.686655</td>\n",
       "      <td>-1.191196</td>\n",
       "      <td>-0.371677</td>\n",
       "      <td>-3.741301</td>\n",
       "      <td>-101.179911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1997-01-01 04:00:00+00:00</td>\n",
       "      <td>DENW094</td>\n",
       "      <td>50.754704</td>\n",
       "      <td>6.093923</td>\n",
       "      <td>-1.686655</td>\n",
       "      <td>-1.191196</td>\n",
       "      <td>-0.371677</td>\n",
       "      <td>-3.768186</td>\n",
       "      <td>-101.179911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    datetime station_code   latitude  longitude        o3  \\\n",
       "0  1997-01-01 00:00:00+00:00      DENW094  50.754704   6.093923 -1.686655   \n",
       "1  1997-01-01 01:00:00+00:00      DENW094  50.754704   6.093923 -1.686655   \n",
       "2  1997-01-01 02:00:00+00:00      DENW094  50.754704   6.093923 -1.686655   \n",
       "3  1997-01-01 03:00:00+00:00      DENW094  50.754704   6.093923 -1.686655   \n",
       "4  1997-01-01 04:00:00+00:00      DENW094  50.754704   6.093923 -1.686655   \n",
       "\n",
       "        no2        no      temp       press  \n",
       "0 -1.191196 -0.371677 -3.566546 -101.179911  \n",
       "1 -1.191196 -0.371677 -3.633759 -101.179911  \n",
       "2 -1.191196 -0.371677 -3.647202 -101.179911  \n",
       "3 -1.191196 -0.371677 -3.741301 -101.179911  \n",
       "4 -1.191196 -0.371677 -3.768186 -101.179911  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "## Normalized data csv is also made available for the select stations in URL:\n",
    "# https://drive.google.com/file/d/1ohReYdUgtBFogeAmxghPo3_Qa9RnzxSh/view?usp=drive_link \n",
    "# or if run locally you can load from the path as below:\n",
    "# e.g. r\"/content/timeseries_data/normalized_data.csv\"\n",
    "dataframes = pd.read_csv(os.path.join(TIMESERIES_DATA_DIR, \"normalized_data.csv\"))\n",
    "dataframes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23efccd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv_labex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
